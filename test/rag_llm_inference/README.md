### Large Language model - Used to generate a response for a given prompt
Install the dependencies in a virtual environment and execute the python script inference.py
```bash 
$ source activate components  # To create a new virtual environment : *conda create -n <env_name>*
$ pip install -r requirements.txt
$ python client.py
```